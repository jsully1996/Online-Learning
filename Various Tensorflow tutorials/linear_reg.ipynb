{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to train a linear regression model\n",
    "Before we begin to train the model, let's have look at what is a linear regression.\n",
    "\n",
    "Imagine you have two variables, x and y and your task is to predict the value of knowing the value of . If you plot the data, you can see a positive relationship between your independent variable, x and your dependent variable y.\n",
    "\n",
    "\n",
    "\n",
    "You may observe, if x=1,y will roughly be equal to 6 and if x=2,y will be around 8.5.\n",
    "\n",
    "This is not a very accurate method and prone to error, especially with a dataset with hundreds of thousands of points.\n",
    "\n",
    "A linear regression is evaluated with an equation. The variable y is explained by one or many covariates. In your example, there is only one dependent variable. If you have to write this equation, it will be:\n",
    "\n",
    "\n",
    "\n",
    "With:\n",
    "\n",
    " is the bias. i.e. if x=0, y=\n",
    " is the weight associated to x\n",
    " is the residual or the error of the model. It includes what the model cannot learn from the data\n",
    "Imagine you fit the model and you find the following solution for:\n",
    "\n",
    " = 3.8\n",
    " = 2.78\n",
    "You can substitute those numbers in the equation and it becomes:\n",
    "\n",
    "y= 3.8 + 2.78x\n",
    "\n",
    "You have now a better way to find the values for y. That is, you can replace x with any value you want to predict y. In the image below, we have replace x in the equation with all the values in the dataset and plot the result.\n",
    "\n",
    "\n",
    "\n",
    "The red line represents the fitted value, that is the values of y for each value of x. You don't need to see the value of x to predict y, for each x there is any which belongs to the red line. You can also predict for values of x higher than 2!\n",
    "\n",
    "If you want to extend the linear regression to more covariates, you can by adding more variables to the model. The difference between traditional analysis and linear regression is the linear regression looks at how y will react for each variable x taken independently.\n",
    "\n",
    "Let's see an example. Imagine you want to predict the sales of an ice cream shop. The dataset contains different information such as the weather (i.e rainy, sunny, cloudy), customer informations (i.e salary, gender, marital status).\n",
    "\n",
    "Traditional analysis will try to predict the sale by let's say computing the average for each variable and try to estimate the sale for different scenarios. It will lead to poor predictions and restrict the analysis to the chosen scenario.\n",
    "\n",
    "If you use linear regression, you can write this equation:\n",
    "\n",
    "\n",
    "\n",
    "The algorithm will find the best solution for the weights; it means it will try to minimize the cost (the difference between the fitted line and the data points).\n",
    "\n",
    "How the algorithm works\n",
    "\n",
    "\n",
    "\n",
    "The algorithm will choose a random number for each  and  and replace the value of x to get the predicted value of y. If the dataset has 100 observations, the algorithm computes 100 predicted values.\n",
    "\n",
    "We can compute the error, noted  of the model, which is the difference between the predicted value and the real value. A positive error means the model underestimates the prediction of y, and a negative error means the model overestimates the prediction of y.\n",
    "\n",
    "\n",
    "\n",
    "Your goal is to minimize the square of the error. The algorithm computes the mean of the square error. This step is called minimization of the error. For linear regression is the Mean Square Error, also called MSE. Mathematically, it is:\n",
    "\n",
    "\n",
    "\n",
    "Where:\n",
    "\n",
    " is the weights so  refers to the predicted value\n",
    "y is the real values\n",
    "m is the number of observations\n",
    "Note that  means it uses the transpose of the matrices. The  is the mathematical notation of the mean.\n",
    "\n",
    "The goal is to find the best  that minimize the MSE\n",
    "\n",
    "If the average error is large, it means the model performs poorly and the weights are not chosen properly. To correct the weights, you need to use an optimizer. The traditional optimizer is called Gradient Descent.\n",
    "\n",
    "The gradient descent takes the derivative and decreases or increases the weight. If the derivative is positive, the weight is decreased. If the derivative is negative, the weight increases. The model will update the weights and recompute the error. This process is repeated until the error does not change anymore. Each process is called an iteration. Besides, the gradients are multiplied by a learning rate. It indicates the speed of the learning.\n",
    "\n",
    "If the learning rate is too small, it will take very long time for the algorithm to converge (i.e requires lots of iterations). If the learning rate is too high, the algorithm might never converge.\n",
    "\n",
    "\n",
    "\n",
    "You can see from the picture above, the model repeats the process about 20 times before to find a stable value for the weights, therefore reaching the lowest error.\n",
    "\n",
    "Note that, the error is not equal to zero but stabilizes around 5. It means, the model makes a typical error of 5. If you want to reduce the error, you need to add more information to the model such as more variables or use different estimators.\n",
    "\n",
    "You remember the first equation\n",
    "\n",
    "\n",
    "\n",
    "The final weights are 3.8 and 2.78. The video below shows you how the gradient descent optimize the loss function to find this weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to train a Linear Regression with TensorFlow\n",
    "Now that you have a better understanding of what is happening behind the hood, you are ready to use the estimator API provided by TensorFlow to train your first linear regression.\n",
    "\n",
    "You will use the Boston Dataset, which includes the following variables\n",
    "\n",
    "crim\tper capita crime rate by town\n",
    "zn\tproportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "indus\tproportion of non-retail business acres per town.\n",
    "nox\tnitric oxides concentration\n",
    "rm\taverage number of rooms per dwelling\n",
    "age\tproportion of owner-occupied units built before 1940\n",
    "dis\tweighted distances to five Boston employment centers\n",
    "tax\tfull-value property-tax rate per dollars 10,000\n",
    "ptratio\tpupil-teacher ratio by town\n",
    "medv\tMedian value of owner-occupied homes in thousand dollars\n",
    "You will create three different datasets:\n",
    "\n",
    "dataset\tobjective\tshape\n",
    "Training\tTrain the model and obtain the weights\t400, 10\n",
    "Evaluation\tEvaluate the performance of the model on unseen data\t100, 10\n",
    "Predict\tUse the model to predict house value on new data\t6, 10\n",
    "The objectives is to use the features of the dataset to predict the value of the house.\n",
    "\n",
    "During the second part of the tutorial, you will learn how to use TensorFlow with three different way to import the data:\n",
    "\n",
    "With Pandas\n",
    "With Numpy\n",
    "Only TF\n",
    "Note that, all options provide the same results.\n",
    "\n",
    "You will learn how to use the high-level API to build, train an evaluate a linear regression model. If you were using the low-level API, you had to define by hand the:\n",
    "\n",
    "Loss function\n",
    "Optimize: Gradient descent\n",
    "Matrices multiplication\n",
    "Graph and tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 10) (100, 10) (6, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.30040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.58</td>\n",
       "      <td>0.605</td>\n",
       "      <td>6.319</td>\n",
       "      <td>96.1</td>\n",
       "      <td>2.1000</td>\n",
       "      <td>403</td>\n",
       "      <td>14.7</td>\n",
       "      <td>23.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.35980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.693</td>\n",
       "      <td>5.887</td>\n",
       "      <td>94.7</td>\n",
       "      <td>1.7821</td>\n",
       "      <td>666</td>\n",
       "      <td>20.2</td>\n",
       "      <td>12.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.12744</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.91</td>\n",
       "      <td>0.448</td>\n",
       "      <td>6.770</td>\n",
       "      <td>2.9</td>\n",
       "      <td>5.7209</td>\n",
       "      <td>233</td>\n",
       "      <td>17.9</td>\n",
       "      <td>26.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.15876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.81</td>\n",
       "      <td>0.413</td>\n",
       "      <td>5.961</td>\n",
       "      <td>17.5</td>\n",
       "      <td>5.2873</td>\n",
       "      <td>305</td>\n",
       "      <td>19.2</td>\n",
       "      <td>21.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.03768</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.404</td>\n",
       "      <td>7.274</td>\n",
       "      <td>38.3</td>\n",
       "      <td>7.3090</td>\n",
       "      <td>329</td>\n",
       "      <td>12.6</td>\n",
       "      <td>34.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       crim    zn  indus    nox     rm   age     dis  tax  ptratio  medv\n",
       "0   2.30040   0.0  19.58  0.605  6.319  96.1  2.1000  403     14.7  23.8\n",
       "1  13.35980   0.0  18.10  0.693  5.887  94.7  1.7821  666     20.2  12.7\n",
       "2   0.12744   0.0   6.91  0.448  6.770   2.9  5.7209  233     17.9  26.6\n",
       "3   0.15876   0.0  10.81  0.413  5.961  17.5  5.2873  305     19.2  21.7\n",
       "4   0.03768  80.0   1.52  0.404  7.274  38.3  7.3090  329     12.6  34.6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COLUMNS = [\"crim\", \"zn\", \"indus\", \"nox\", \"rm\", \"age\",\n",
    "           \"dis\", \"tax\", \"ptratio\", \"medv\"]\n",
    "training_set = pd.read_csv(\"boston_data/boston_train.csv\", skipinitialspace=True,skiprows=1, names=COLUMNS)\n",
    "test_set = pd.read_csv(\"boston_data/boston_test.csv\", skipinitialspace=True,skiprows=1, names=COLUMNS)\n",
    "prediction_set = pd.read_csv(\"boston_data/boston_predict.csv\", skipinitialspace=True,skiprows=1, names=COLUMNS)\n",
    "print(training_set.shape, test_set.shape, prediction_set.shape)\t\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = [\"crim\", \"zn\", \"indus\", \"nox\", \"rm\",\n",
    "                 \"age\", \"dis\", \"tax\", \"ptratio\"]\n",
    "LABEL = \"medv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2) Convert the data\n",
    "\n",
    "You need to convert the numeric variables in the proper format. Tensorflow provides a method to convert continuous variable: tf.feature_column.numeric_column().\n",
    "\n",
    "In the previous step, you define a list a feature you want to include in the model. Now you can use this list to convert them into numeric data. If you want to exclude features in your model, feel free to drop one or more variables in the list FEATURES before you construct the feature_cols\n",
    "\n",
    "Note that you will use Python list comprehension with the list FEATURES to create a new list named feature_cols. It helps you avoid writing nine times tf.feature_column.numeric_column(). A list comprehension is a faster and cleaner way to create new lists\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NumericColumn(key='crim', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='zn', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='indus', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='nox', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='rm', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='dis', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='tax', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " NumericColumn(key='ptratio', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_cols = [tf.feature_column.numeric_column(k) for k in FEATURES]\n",
    "feature_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3) Define the estimator\n",
    "\n",
    "In this step, you need to define the estimator. Tensorflow currently provides 6 pre-built estimators, including 3 for classification task and 3 for regression task:\n",
    "\n",
    "Regressor\n",
    "DNNRegressor\n",
    "LinearRegressor\n",
    "DNNLineaCombinedRegressor\n",
    "Classifier\n",
    "DNNClassifier\n",
    "LinearClassifier\n",
    "DNNLineaCombinedClassifier\n",
    "In this tutorial, you will use the Linear Regressor. To access this function, you need to use tf.estimator.\n",
    "\n",
    "The function needs two arguments:\n",
    "\n",
    "feature_columns: Contains the variables to include in the model\n",
    "model_dir: path to store the graph, save the model parameters, etc\n",
    "Tensorflow will automatically create a file named train in your working directory. You need to use this path to access the Tensorboard.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'train', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000019A51D17208>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearRegressor at 0x19a50538eb8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = tf.estimator.LinearRegressor(    \n",
    "        feature_columns=feature_cols,   \n",
    "        model_dir=\"train\")\n",
    "estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tricky part with TensorFlow is the way to feed the model. Tensorflow is designed to work with parallel computing and very large dataset. Due to the limitation of the machine resources, it is impossible to feed the model with all the data at once. For that, you need to feed a batch of data each time. Note that, we are talking about huge dataset with millions or more records. If you don't add batch, you will end up with a memory error.\n",
    "\n",
    "For instance, if your data contains 100 observations and you define a batch size of 10, it means the model will see 10 observations for each iteration (10*10).\n",
    "\n",
    "When the model has seen all the data, it finishes one epoch. An epoch defines how many times you want the model to see the data. It is better to set this step to none and let the model performs iteration number of time.\n",
    "\n",
    "A second information to add is if you want to shuffle the data before each iteration. During the training, it is important to shuffle the data so that the model does not learn specific pattern of the dataset. If the model learns the details of the underlying pattern of the data, it will have difficulties to generalize the prediction for unseen data. This is called overfitting. The model performs well on the training data but cannot predict correctly for unseen data.\n",
    "\n",
    "TensorFlow makes this two steps easy to do. When the data goes to the pipeline, it knows how many observations it needs (batch) and if it has to shuffle the data.\n",
    "\n",
    "To instruct Tensorflow how to feed the model, you can use pandas_input_fn. This object needs 5 parameters:\n",
    "\n",
    "x: feature data\n",
    "y: label data\n",
    "batch_size: batch. By default 128\n",
    "num_epoch: Number of epoch, by default 1\n",
    "shuffle: Shuffle or not the data. By default, None\n",
    "You need to feed the model many times so you define a function to repeat this process. all this function get_input_fn.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_fn(data_set, num_epochs=None, n_batch = 128, shuffle=True):    \n",
    "         return tf.estimator.inputs.pandas_input_fn(       \n",
    "         x=pd.DataFrame({k: data_set[k].values for k in FEATURES}),       \n",
    "         y = pd.Series(data_set[LABEL].values),       \n",
    "         batch_size=n_batch,          \n",
    "         num_epochs=num_epochs,       \n",
    "         shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The usual method to evaluate the performance of a model is to:\n",
    "\n",
    "Train the model\n",
    "Evaluate the model in a different dataset\n",
    "Make prediction\n",
    "Tensorflow estimator provides three different functions to carry out this three steps easily.\n",
    "\n",
    "Step 4): Train the model\n",
    "\n",
    "You can use the estimator train to evaluate the model. The train estimator needs an input_fn and a number of steps. You can use the function you created above to feed the model. Then, you instruct the model to iterate 1000 times. Note that, you don't specify the number of epochs, you let the model iterates 1000 times. If you set the number of epoch to 1, then the model will iterate 4 times: There are 400 records in the training set, and the batch size is 128\n",
    "\n",
    "128 rows\n",
    "128 rows\n",
    "128 rows\n",
    "16 rows\n",
    "Therefore, it is easier to set the number of epoch to none and define the number of iteration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jamkha\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From C:\\Users\\Jamkha\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From C:\\Users\\Jamkha\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\inputs\\queues\\feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Entity <bound method LinearModel.call of <tensorflow.python.feature_column.feature_column_v2.LinearModel object at 0x0000019A526AD828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LinearModel.call of <tensorflow.python.feature_column.feature_column_v2.LinearModel object at 0x0000019A526AD828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LinearModel.call of <tensorflow.python.feature_column.feature_column_v2.LinearModel object at 0x0000019A526AD828>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LinearModel.call of <tensorflow.python.feature_column.feature_column_v2.LinearModel object at 0x0000019A526AD828>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method _LinearModelLayer.call of <tensorflow.python.feature_column.feature_column_v2._LinearModelLayer object at 0x0000019A526E4128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method _LinearModelLayer.call of <tensorflow.python.feature_column.feature_column_v2._LinearModelLayer object at 0x0000019A526E4128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method _LinearModelLayer.call of <tensorflow.python.feature_column.feature_column_v2._LinearModelLayer object at 0x0000019A526E4128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method _LinearModelLayer.call of <tensorflow.python.feature_column.feature_column_v2._LinearModelLayer object at 0x0000019A526E4128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From C:\\Users\\Jamkha\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\canned\\linear.py:308: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "WARNING:tensorflow:From C:\\Users\\Jamkha\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From C:\\Users\\Jamkha\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:875: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into train\\model.ckpt.\n",
      "INFO:tensorflow:loss = 83729.64, step = 1\n",
      "INFO:tensorflow:global_step/sec: 268.864\n",
      "INFO:tensorflow:loss = 13909.657, step = 101 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 455.406\n",
      "INFO:tensorflow:loss = 12881.449, step = 201 (0.219 sec)\n",
      "INFO:tensorflow:global_step/sec: 474.924\n",
      "INFO:tensorflow:loss = 12391.541, step = 301 (0.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 470.442\n",
      "INFO:tensorflow:loss = 12050.5625, step = 401 (0.213 sec)\n",
      "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 404 vs previous value: 404. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
      "INFO:tensorflow:global_step/sec: 459.603\n",
      "INFO:tensorflow:loss = 11766.134, step = 501 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.6\n",
      "INFO:tensorflow:loss = 11509.922, step = 601 (0.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 348.72\n",
      "INFO:tensorflow:loss = 11272.889, step = 701 (0.291 sec)\n",
      "INFO:tensorflow:global_step/sec: 447.241\n",
      "INFO:tensorflow:loss = 11051.9795, step = 801 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 459.604\n",
      "INFO:tensorflow:loss = 10845.855, step = 901 (0.217 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into train\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5925.9873.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.linear.LinearRegressor at 0x19a50538eb8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.train(input_fn=get_input_fn(training_set,                                       \n",
    "                                           num_epochs=None,                                      \n",
    "                                           n_batch = 128,                                      \n",
    "                                           shuffle=False),                                      \n",
    "                                           steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5) Evaluate your model\n",
    "\n",
    "You can evaluate the fit of your model on the test set with the code below:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Entity <bound method LinearModel.call of <tensorflow.python.feature_column.feature_column_v2.LinearModel object at 0x0000019A5444D7B8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LinearModel.call of <tensorflow.python.feature_column.feature_column_v2.LinearModel object at 0x0000019A5444D7B8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LinearModel.call of <tensorflow.python.feature_column.feature_column_v2.LinearModel object at 0x0000019A5444D7B8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LinearModel.call of <tensorflow.python.feature_column.feature_column_v2.LinearModel object at 0x0000019A5444D7B8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method _LinearModelLayer.call of <tensorflow.python.feature_column.feature_column_v2._LinearModelLayer object at 0x0000019A5449E4A8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method _LinearModelLayer.call of <tensorflow.python.feature_column.feature_column_v2._LinearModelLayer object at 0x0000019A5449E4A8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method _LinearModelLayer.call of <tensorflow.python.feature_column.feature_column_v2._LinearModelLayer object at 0x0000019A5449E4A8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method _LinearModelLayer.call of <tensorflow.python.feature_column.feature_column_v2._LinearModelLayer object at 0x0000019A5449E4A8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-09-19T12:47:07Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From C:\\Users\\Jamkha\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from train\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-09-19-12:47:08\n",
      "INFO:tensorflow:Saving dict for global step 1000: average_loss = 32.15896, global_step = 1000, label/mean = 22.08, loss = 3215.896, prediction/mean = 22.404533\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: train\\model.ckpt-1000\n"
     ]
    }
   ],
   "source": [
    "ev = estimator.evaluate(    \n",
    "          input_fn=get_input_fn(test_set,                          \n",
    "          num_epochs=1,                          \n",
    "          n_batch = 128,                          \n",
    "          shuffle=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can print the loss with the code below:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3215.895996\n"
     ]
    }
   ],
   "source": [
    "loss_score = ev[\"loss\"]\n",
    "print(\"Loss: {0:f}\".format(loss_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has a loss of 3215. You can check the summary statistic to get an idea of how big the error is.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    400.000000\n",
       "mean      22.625500\n",
       "std        9.572593\n",
       "min        5.000000\n",
       "25%       16.600000\n",
       "50%       21.400000\n",
       "75%       25.025000\n",
       "max       50.000000\n",
       "Name: medv, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set['medv'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6) Make the prediction\n",
    "\n",
    "Finally, you can use the estimator predict to estimate the value of 6 Boston houses.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Entity <bound method LinearModel.call of <tensorflow.python.feature_column.feature_column_v2.LinearModel object at 0x0000019A52C67400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LinearModel.call of <tensorflow.python.feature_column.feature_column_v2.LinearModel object at 0x0000019A52C67400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method LinearModel.call of <tensorflow.python.feature_column.feature_column_v2.LinearModel object at 0x0000019A52C67400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method LinearModel.call of <tensorflow.python.feature_column.feature_column_v2.LinearModel object at 0x0000019A52C67400>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method _LinearModelLayer.call of <tensorflow.python.feature_column.feature_column_v2._LinearModelLayer object at 0x0000019A52C67710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method _LinearModelLayer.call of <tensorflow.python.feature_column.feature_column_v2._LinearModelLayer object at 0x0000019A52C67710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method _LinearModelLayer.call of <tensorflow.python.feature_column.feature_column_v2._LinearModelLayer object at 0x0000019A52C67710>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method _LinearModelLayer.call of <tensorflow.python.feature_column.feature_column_v2._LinearModelLayer object at 0x0000019A52C67710>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from train\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Predictions: [array([32.297546], dtype=float32), array([18.96125], dtype=float32), array([27.270979], dtype=float32), array([29.299236], dtype=float32), array([16.436684], dtype=float32), array([21.460876], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "y = estimator.predict(    \n",
    "         input_fn=get_input_fn(prediction_set,                          \n",
    "         num_epochs=1,                          \n",
    "         n_batch = 128,                          \n",
    "         shuffle=False))\n",
    "predictions = list(p[\"predictions\"] for p in itertools.islice(y, 6))\n",
    "print(\"Predictions: {}\".format(str(predictions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
