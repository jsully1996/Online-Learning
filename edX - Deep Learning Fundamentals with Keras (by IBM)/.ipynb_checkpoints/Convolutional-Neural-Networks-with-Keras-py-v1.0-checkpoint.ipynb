{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://cognitiveclass.ai\"><img src = \"https://ibm.box.com/shared/static/9gegpsmnsoo25ikkbl4qzlvlyjbgxs5x.png\" width = 400> </a>\n",
    "\n",
    "<h1 align=center><font size = 5>Convolutional Neural Networks with Keras</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will learn how to use the keras library to build convolutional neural networks. We will also use the popular MNIST dataset and we will compare our results to using a conventional neural network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "<font size = 3>\n",
    "      \n",
    "1. <a href=\"#item2\">Import Keras and Packages</a>   \n",
    "2. <a href=\"#item3\">Convolutional Neural Network with One Convolutional and Pooling Layers</a>  \n",
    "3. <a href=\"#item4\">Convolutional Neural Network with Two Convolutional and Pooling Layers</a>  \n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Keras and Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing the keras libraries and the packages that we would need to build a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#from keras.models import Sequential\n",
    "#from keras.layers import Dense\n",
    "#from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with convolutional neural networks in particular, we will need additional packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Layer with two sets of convolutional and pooling layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's normalize the pixel values to be between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255 # normalize training data\n",
    "X_test = X_test / 255 # normalize test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's convert the target variable into binary categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "num_classes = y_test.shape[1] # number of categories\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's define a function that creates our model. Let's start with one set of convolutional and pooling layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_model():\n",
    "    \n",
    "    # create model\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(filters=16,kernel_size=(3,3),strides=(1,1),activation='relu',input_shape=(28,28,1)),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "        \n",
    "        tf.keras.layers.Flatten(),\n",
    "        \n",
    "        tf.keras.layers.Dense(units=100,activation='relu'),\n",
    "        tf.keras.layers.Dense(units=num_classes,activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # compile model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's call the function to create the model, and then let's train it and evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jamkha\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 - 12s - loss: 0.3356 - acc: 0.9047 - val_loss: 0.1278 - val_acc: 0.9616\n",
      "Epoch 2/10\n",
      "60000/60000 - 11s - loss: 0.1031 - acc: 0.9702 - val_loss: 0.0715 - val_acc: 0.9780\n",
      "Epoch 3/10\n",
      "60000/60000 - 12s - loss: 0.0658 - acc: 0.9807 - val_loss: 0.0541 - val_acc: 0.9818\n",
      "Epoch 4/10\n",
      "60000/60000 - 12s - loss: 0.0507 - acc: 0.9852 - val_loss: 0.0500 - val_acc: 0.9836\n",
      "Epoch 5/10\n",
      "60000/60000 - 12s - loss: 0.0413 - acc: 0.9882 - val_loss: 0.0472 - val_acc: 0.9839\n",
      "Epoch 6/10\n",
      "60000/60000 - 11s - loss: 0.0339 - acc: 0.9900 - val_loss: 0.0547 - val_acc: 0.9817\n",
      "Epoch 7/10\n",
      "60000/60000 - 12s - loss: 0.0287 - acc: 0.9918 - val_loss: 0.0455 - val_acc: 0.9834\n",
      "Epoch 8/10\n",
      "60000/60000 - 12s - loss: 0.0241 - acc: 0.9928 - val_loss: 0.0448 - val_acc: 0.9845\n",
      "Epoch 9/10\n",
      "60000/60000 - 12s - loss: 0.0208 - acc: 0.9938 - val_loss: 0.0447 - val_acc: 0.9849\n",
      "Epoch 10/10\n",
      "60000/60000 - 13s - loss: 0.0172 - acc: 0.9952 - val_loss: 0.0476 - val_acc: 0.9844\n",
      "Accuracy: 0.9843999743461609 \n",
      " Error: 1.5600025653839111\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = convolutional_model()\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Layer with two sets of convolutional and pooling layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's redefine our convolutional model so that it has two convolutional and pooling layers instead of just one layer of each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_model_new():\n",
    "    \n",
    "    # create model\n",
    "    model_new = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(filters=16,kernel_size=(3,3),activation='relu',input_shape=(28,28,1)),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(filters=16,kernel_size=(5,5),activation='relu'),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "        \n",
    "        tf.keras.layers.Flatten(),\n",
    "        \n",
    "        tf.keras.layers.Dense(units=100,activation='relu'),\n",
    "        tf.keras.layers.Dense(units=num_classes,activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model_new.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 9, 9, 16)          6416      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               25700     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 33,286\n",
      "Trainable params: 33,286\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model_new = convolutional_model_new()\n",
    "model_new.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's call the function to create our new convolutional neural network, and then let's train it and evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 - 11s - loss: 0.0139 - acc: 0.9962 - val_loss: 0.0460 - val_acc: 0.9853\n",
      "Epoch 2/10\n",
      "60000/60000 - 11s - loss: 0.0115 - acc: 0.9971 - val_loss: 0.0447 - val_acc: 0.9853\n",
      "Epoch 3/10\n",
      "60000/60000 - 12s - loss: 0.0095 - acc: 0.9977 - val_loss: 0.0446 - val_acc: 0.9854\n",
      "Epoch 4/10\n",
      "60000/60000 - 13s - loss: 0.0074 - acc: 0.9983 - val_loss: 0.0475 - val_acc: 0.9860\n",
      "Epoch 5/10\n",
      "60000/60000 - 13s - loss: 0.0077 - acc: 0.9979 - val_loss: 0.0494 - val_acc: 0.9854\n",
      "Epoch 6/10\n",
      "60000/60000 - 13s - loss: 0.0056 - acc: 0.9987 - val_loss: 0.0486 - val_acc: 0.9864\n",
      "Epoch 7/10\n",
      "60000/60000 - 15s - loss: 0.0042 - acc: 0.9991 - val_loss: 0.0466 - val_acc: 0.9869\n",
      "Epoch 8/10\n",
      "60000/60000 - 14s - loss: 0.0030 - acc: 0.9995 - val_loss: 0.0511 - val_acc: 0.9856\n",
      "Epoch 9/10\n",
      "60000/60000 - 21s - loss: 0.0041 - acc: 0.9990 - val_loss: 0.0581 - val_acc: 0.9831\n",
      "Epoch 10/10\n",
      "60000/60000 - 22s - loss: 0.0040 - acc: 0.9990 - val_loss: 0.0618 - val_acc: 0.9832\n",
      "Accuracy: 0.9832000136375427 \n",
      " Error: 1.6799986362457275\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: {} \\n Error: {}\".format(scores[1], 100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is part of a course on **edX** called *Deep Learning Fundamentals with Keras*. If you accessed this notebook outside the course, you can take this course online by clicking [here](http://cocl.us/DL0101EN_edX_Week4_LAB1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "Copyright &copy; 2018 [IBM Developer Skills Network](https://cognitiveclass.ai/?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
